---
title: "Non-disclosive Exposome analysis using Google Cloud and dsExposome"
author:
  - name: Xavier Escribà Montagut
    affiliations:
      - name: ISGlobal
  - name: Juan R. Gonzàlez
    affiliations:
      - name: ISGlobal
format:
  html:
    toc: true
    output-file: "index"
execute: 
  cache: true
---

## Computing issues when using DataSHIELD in large consortia

DataSHIELD is a technical solution for analyzing sensitive or confidential data in a federated manner, where data remains in the control of the original data holders and is not centralized or shared. One of the main problems with using DataSHIELD in large projects is the limited computing capacities of the individual data holders. Since the data is not centralized, the analysis must be performed on each site separately and then non-disclosive results are combined. This can lead to longer analysis times and increased computational burden on the individual sites, which may not have the same level of computing resources. Additionally, the data holders may have different technical capabilities, which can make it difficult to standardize the analysis across sites and ensure that the results are comparable. Furthermore, the security and privacy concerns around sensitive data can make it difficult to share data across sites, which can limit the ability to perform advanced or complex analysis.

In this report we provide a possible solution using Google Cloud which is a suite of cloud computing services offered by Google that provides a variety of tools and resources for businesses and organizations. The services include infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS) offerings. The IaaS component of Google Cloud, called Google Compute Engine, allows users to rent virtual machines on which to run their own applications.

Google Cloud also provides a variety of security and compliance features to help protect user's data and applications which is one of the main concerns of researchers for using this solution. Importantly, Google Cloud is compliant with the General Data Protection Regulation (GDPR) and takes a number of steps and features to ensure the security of user data.These include:

-   Data processing agreements (DPAs) that outline how Google Cloud processes customer data in compliance with GDPR
-   Data protection impact assessments (DPIAs) that help customers identify and mitigate data protection risks
-   Tools for managing user consent and data subject rights, such as the ability to delete or export personal data
-   Transparency reports that provide information on data requests from government and other third parties.

In terms of security, Google Cloud has a number of measures in place to protect user data. These include:

-   Encryption of data in transit and at rest
-   Regular security assessments and penetration testing to identify and address vulnerabilities
-   Access controls and authentication to ensure that only authorized users can access data
-   Network security to protect against external threats
-   A dedicated security team that monitors for and responds to potential security incidents.
-   Google Cloud is also SOC2, ISO 27001, and PCI DSS certified, which are internationally recognized standards for information security management. Furthermore, it also provides a variety of tools and services to help customers manage their own security, such as security key management service, Cloud Security Command Center, and Cloud Identity-Aware Proxy.

More details about Google Cloud Compliance (also specific for countries) can be found [here](https://cloud.google.com/security/compliance).

All the above mentioned features make possible to evaluate the possibility of using Google Cloud within [ATHLETE project](https://athleteproject.eu/) for some cohorts to overcome their existing computing problems. In order to illustrate how we can set up ATHLETE's infrastructure, next we describe an infrastructure we set up using data from [HELIX project](http://www.projecthelix.eu/es) in which each cohort was consider as a different cohort.

## Meet Google Cloud

[Google Cloud](cloud.google.com) is a cloud-based computing platform that offers a wide variety of services. For this demonstration, we have spined-up a simple `Compute Engine` with `debian-11-bullseye-v20221206` and `docker 20.10.22`.

This is basically a server instance similar to what could be found in a typical research institution, but instead of being on-premises, it is hosted on the cloud by Google.

Hardware wise, we have used a 4 core 16GB RAM instance with 50GB of SSD storage. At the time of writing, such specs are billed at \~120 USD per month.

## Infrastructure

With Google Cloud technology, we deployed a working prototype of Opal+ DataSHIELD. We have created a simple infrastructure with synthetic Exposome data from the HELIX project. This is to portray how a cohort interested on using DataSHIELD for their analysis could deploy the service without the need of buying additional on-premises computational resources.

The Opal deployment on the Google Cloud server has been performed using the Coral stack (version 5.3.0), which is composed by a series of interconnected Docker containers with all the required services to host the dataset and analyze them using DataSHIELD.

In order to visualize all the infrastructure and how it is interconnected, please take a look at the following figure. On the figure there are described two very distinct parts **1)** The computer of the researcher, which is running the client side R packages that perform the connection to Opal and send to it the analysis commands, and **2)** the Google Cloud instance, where we have all the analysis services and dataset encrypted by Google, the raw data will never leave that safe enclosure.

![](Figures/infrastructure.png)

## Exposome analysis

In order to demonstrate the proposed solution, we will perform basic data exploration and ExWAS to the synthetic Exposome data placed on the Google Cloud instance. If the reader has further interest, please feel free to read about [Exposome analysis capabilities](https://isglobal-brge.github.io/dsExposomeClient/articles/dsExposome.html) and [details on how DataSHIELD works](https://data2knowledge.atlassian.net/wiki/spaces/DSDEV/pages/931069953/Beginners+Tutorial+DataSHIELD+v6.1).

### Connecting to the Opal server

The first step is to login to the server. You can see that we are connecting to a fixed IP (`35.219.173.160`). It is good to remark that it is **fixed**, so that if we try to login after two months the address will still work, typically we are assigned dynamic IPs that change over time. Google Cloud is able to provide fixed IPs with just the click of a button, making it easier for the IT departments to provide a DNS (i.e. to be able to use `opal.isglobal.org` instead of an IP).

We have created a test user with DataSHIELD access to the server.

```{r}
#| output: false
require('DSI')
require('DSOpal')
require('dsBaseClient')
require('dsExposomeClient')

user <- "test"
pass <- "Testtest1!"

library(httr);set_config(config(ssl_verifypeer = 0L))

builder <- DSI::newDSLoginBuilder()
builder$append(server = 'server1', 
               url = "https://35.219.173.160/repo",
               user = user, 
               password = pass, 
               profile = "default")
logindata <- builder$build()
conns <- DSI::datashield.login(logins = logindata, assign = F)
```

### Assigning the resource

Now that we have successfully connected to the server, we just have to specify which data to load in order to analyze it.

```{r}
datashield.assign.resource(
  conns, 
  symbol = 'exposome_resource', 
  resource = list(server1 = 'EXPOSOME.exposomeSet')
)
ds.class("exposome_resource")

datashield.assign.expr(
  conns, 
  symbol = "exposome_resource", 
  expr = quote(as.resource.object(exposome_resource))
)
ds.class("exposome_resource")
```

### Working with the data

Finally, we are ready to start analyzing. Here we can see the summary of one variable of the Exposome.

```{r}
ds.exposome_summary("exposome_resource", "AbsPM25")
```

Now, we will see the amount of missings on the phenotype data.

```{r}
phenos <- ds.tableMissings("exposome_resource", set = "phenotypes")
ds.plotMissings(phenos)
```

And finally we will perform a simple ExWAS analysis.

```{r}
#| output: false
exwas_results <- ds.exwas(
  "blood_pre ~ sex", 
  Set = "exposome_resource", 
  family = "gaussian",
  type = "meta"
)
```

```{r}
ds.plotExwas(exwas_results, type="manhattan")
```

When we are finished doing analysis, it is a good practice to logout of the server, that way the computational resources will be released for other researchers to use.

```{r}
datashield.logout(conns)
```
